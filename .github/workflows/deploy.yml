name: Run Training (ECS via Capacity Provider)

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "training mode (e.g., train, test)"
        required: true
        default: "train"
      image_tag:
        description: "ECR image tag OR sha256 digest (e.g., latest OR sha256:...)"
        required: true
        default: "latest"
      enforce_single_instance:
        description: "Set ASG max=1, desired=1 before run to avoid scaling above 1"
        required: false
        default: "true"
      scale_down:
        description: "Scale ASG to zero after run if cluster is idle"
        required: false
        default: "true"

env:
  AWS_REGION: us-east-2
  ECR_REPOSITORY: protov3
  AWS_ROLE_NAME: GitHubActionsDeployRole       # role must exist and have trust policy
  CLUSTER: proto-phi                           # <-- set me
  CP_NAME: Infra-ECS-Cluster-proto-phi-8fb98b30-AsgCapacityProvider-8II2wKNv8Crf  # <-- set me
  SUBNETS: subnet-0d2d641cd7ec72a28,subnet-00ec8c2e5a55e3c1a,subnet-0b51407e801e66f06  # private subnets (comma, no spaces)
  SECURITY_GROUPS: sg-0b6cbfe847a1bf123        # security group id
  LOG_GROUP: /ecs/                             # pre-create or allow creation in exec role

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # for AWS OIDC

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ env.AWS_ROLE_NAME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Patch task def with ECR image (tag/digest-safe, pin by digest)
        id: patch
        shell: bash
        run: |
          set -euo pipefail

          ACCT="${{ secrets.AWS_ACCOUNT_ID }}"
          REG="${{ env.AWS_REGION }}"
          REPO="${{ env.ECR_REPOSITORY }}"
          RAW_TAG="$(printf '%s' "${{ github.event.inputs.image_tag }}" | tr -d '[:space:]')"
          BASE="${ACCT}.dkr.ecr.${REG}.amazonaws.com/${REPO}"
          IMAGE=""

          # If the input is already a full ref, keep it verbatim
          if [[ "$RAW_TAG" =~ ^[0-9]{12}\.dkr\.ecr\.[a-z0-9-]+\.amazonaws\.com/[a-z0-9._/-]+(:[A-Za-z0-9._-]+|@sha256:[a-f0-9]{64})$ ]]; then
            IMAGE="$RAW_TAG"

          # If it's a bare digest like sha256:abc..., use @digest form
          elif [[ "$RAW_TAG" =~ ^sha256:[a-f0-9]{64}$ ]]; then
            IMAGE="${BASE}@${RAW_TAG}"

          # Otherwise treat as a tag
          else
            IMAGE="${BASE}:${RAW_TAG}"

            # (Optional but recommended) Resolve tag to digest and pin by digest
            DIGEST="$(aws ecr describe-images \
              --repository-name "${REPO}" \
              --image-ids imageTag="${RAW_TAG}" \
              --query 'imageDetails[0].imageDigest' --output text || true)"
            if [[ "$DIGEST" != "None" && "$DIGEST" != "" ]]; then
              IMAGE="${BASE}@${DIGEST}"
            fi
          fi

          # Final validation: either :tag OR @sha256:digest (not both), all lowercase repo
          if ! [[ "$IMAGE" =~ ^[0-9]{12}\.dkr\.ecr\.[a-z0-9-]+\.amazonaws\.com/[a-z0-9._/-]+(:[A-Za-z0-9._-]+|@sha256:[a-f0-9]{64})$ ]]; then
            echo "Rendered invalid image reference: '$IMAGE'" >&2
            exit 1
          fi

          # Apply account ID replacement and set image in TD
          sed "s#<ACCOUNT_ID>#${ACCT}#g" config/task_def.json \
            | jq --arg img "$IMAGE" '.containerDefinitions[0].image = $img' > taskdef.out.json

          echo "Using image: $IMAGE"
          echo "image=$IMAGE" >> "$GITHUB_OUTPUT"

      - name: Register task definition revision
        id: reg
        run: |
          ARN=$(aws ecs register-task-definition \
            --cli-input-json file://taskdef.out.json \
            --query 'taskDefinition.taskDefinitionArn' --output text)
          echo "Registered: $ARN"
          echo "taskdef_arn=$ARN" >> "$GITHUB_OUTPUT"

      - name: Show stored image in registered task def
        run: |
          aws ecs describe-task-definition \
            --task-definition "${{ steps.reg.outputs.taskdef_arn }}" \
            --query 'taskDefinition.containerDefinitions[0].image' --output text

      - name: Enforce single-instance capacity (ASG max=1 desired=1)
        if: github.event.inputs.enforce_single_instance == 'true'
        run: |
          ASG_ARN=$(aws ecs describe-capacity-providers --capacity-providers "${{ env.CP_NAME }}" --query 'capacityProviders[0].autoScalingGroupProvider.autoScalingGroupArn' --output text)
          ASG_NAME=$(echo "$ASG_ARN" | awk -F'autoScalingGroupName/' '{print $2}')
          aws autoscaling update-auto-scaling-group --auto-scaling-group-name "$ASG_NAME" --min-size 0 --max-size 1 --desired-capacity 1
          echo "ASG $ASG_NAME set to max=1 desired=1"

      - name: Run task via Capacity Provider (secrets from GitHub)
        id: run
        run: |
          # Build container env overrides; container name must match "train"
          OVERRIDES=$(jq -n \
            --arg mode "${{ github.event.inputs.mode }}" \
            --arg s3   "${{ secrets.S3_BUCKET }}" \
            --arg wandb "${{ secrets.WANDB_API_KEY }}" \
            '{ containerOverrides: [ { name: "train",
                environment: [
                  {name:"MODE",value:$mode},
                  {name:"S3_BUCKET",value:$s3},
                  {name:"WANDB_API_KEY",value:$wandb}
                ] } ] }')

          TASK_ARN=$(aws ecs run-task \
            --cluster "${{ env.CLUSTER }}" \
            --task-definition "${{ steps.reg.outputs.taskdef_arn }}" \
            --capacity-provider-strategy capacityProvider=${{ env.CP_NAME }},weight=1 \
            --count 1 \
            --network-configuration "awsvpcConfiguration={subnets=[${{ env.SUBNETS }}],securityGroups=[${{ env.SECURITY_GROUPS }}],assignPublicIp=DISABLED}" \
            --overrides "$OVERRIDES" \
            --query 'tasks[0].taskArn' --output text)

          echo "Launched: $TASK_ARN"
          echo "task_arn=$TASK_ARN" >> "$GITHUB_OUTPUT"

      - name: Wait and fail on non-zero exit
        run: |
          set +e
          CLUSTER="${{ env.CLUSTER }}"
          TASK_ARN="${{ steps.run.outputs.task_arn }}"
          TIMEOUT_SEC=$((60 * 180))
          SLEEP=30
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT_SEC ]; do
            DESC=$(aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN")
            echo "$DESC" > task-desc.json
            STATUS=$(echo "$DESC" | jq -r '.tasks[0].lastStatus')
            CONT_STATUS=$(echo "$DESC" | jq -r '.tasks[0].containers[0].lastStatus // ""')
            CONT_REASON=$(echo "$DESC" | jq -r '.tasks[0].containers[0].reason // ""')
            ENI_STATUS=$(echo "$DESC" | jq -r '.tasks[0].attachments[0].status // ""')
            echo "lastStatus=$STATUS contStatus=$CONT_STATUS eni=$ENI_STATUS reason=$CONT_REASON elapsed=${ELAPSED}s"
            [ "$STATUS" = "STOPPED" ] && break
            sleep $SLEEP
            ELAPSED=$(( ELAPSED + SLEEP ))
          done
          if [ "$STATUS" != "STOPPED" ]; then
            echo "Timed out waiting for STOPPED"
            exit 255
          fi
          EXIT=$(jq -r '.tasks[0].containers[0].exitCode // empty' task-desc.json)
          REASON=$(jq -r '.tasks[0].stoppedReason // ""' task-desc.json)
          echo "ExitCode=$EXIT  Reason=$REASON"
          test "$EXIT" = "0"

      - name: Print last 200 log lines (best-effort)
        if: always()
        run: |
          TID=$(echo "${{ steps.run.outputs.task_arn }}" | awk -F'/' '{print $NF}')
          aws logs describe-log-streams --log-group-name "${{ env.LOG_GROUP }}" \
            --log-stream-name-prefix "train/train/$TID" \
            --query 'logStreams[0].logStreamName' --output text > stream.txt || true
          if [ -s stream.txt ]; then
            aws logs get-log-events --log-group-name "${{ env.LOG_GROUP }}" \
              --log-stream-name "$(cat stream.txt)" --limit 200 \
              --query 'events[].message' --output text || true
          fi

      - name: Optionally scale ASG to 0 if cluster idle
        if: always() && github.event.inputs.scale_down == 'true'
        run: |
          RUNNING=$(aws ecs list-tasks --cluster "${{ env.CLUSTER }}" --desired-status RUNNING --query 'taskArns' --output json)
          PENDING=$(aws ecs list-tasks --cluster "${{ env.CLUSTER }}" --desired-status PENDING --query 'taskArns' --output json)
          if [ "$RUNNING" = "[]" ] && [ "$PENDING" = "[]" ]; then
            ASG_ARN=$(aws ecs describe-capacity-providers --capacity-providers "${{ env.CP_NAME }}" --query 'capacityProviders[0].autoScalingGroupProvider.autoScalingGroupArn' --output text)
            ASG_NAME=$(echo "$ASG_ARN" | awk -F'autoScalingGroupName/' '{print $2}')
            aws autoscaling update-auto-scaling-group --auto-scaling-group-name "$ASG_NAME" --min-size 0 --desired-capacity 0
            echo "Scaled ASG $ASG_NAME to 0"
          else
            echo "Cluster not idle; skipping scale-down."
          fi
