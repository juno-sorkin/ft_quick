name: Run Training (ECS via Capacity Provider)

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "training mode (e.g., train, test)"
        required: true
        default: "train"
      image_tag:
        description: "ECR image tag (e.g., latest or a SHA)"
        required: true
        default: "latest"
      enforce_single_instance:
        description: "Set ASG max=1, desired=1 before run to avoid scaling above 1"
        required: false
        default: "true"
      scale_down:
        description: "Scale ASG to zero after run if cluster is idle"
        required: false
        default: "true"

env:
  AWS_REGION: us-east-2
  ECR_REPOSITORY: protov3
  AWS_ROLE_NAME: GitHubActionsDeployRole   # role must exist and have trust policy
  CLUSTER: proto-phi              # <-- set me
  CP_NAME: Infra-ECS-Cluster-proto-phi-8fb98b30-AsgCapacityProvider-8II2wKNv8Crf        # <-- set me (the one wired to your ASG)
  SUBNETS: subnet-0d2d641cd7ec72a28,subnet-00ec8c2e5a55e3c1a,subnet-0b51407e801e66f06      # <-- private subnets, comma-separated (no spaces)
  SECURITY_GROUPS: 	sg-0b6cbfe847a1bf123        # <-- security group id
  LOG_GROUP: /ecs/                       # <-- pre-create or allow creation in exec role

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # for AWS OIDC

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ env.AWS_ROLE_NAME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Patch task def with ECR image tag
        run: |
          IMAGE="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.ECR_REPOSITORY }}:${{ github.event.inputs.image_tag }}"
          sed "s#<ACCOUNT_ID>#${{ secrets.AWS_ACCOUNT_ID }}#g" config/task_def.json \
            | jq --arg img "$IMAGE" '.containerDefinitions[0].image = $img' > taskdef.out.json
          echo "Using image: $IMAGE"

      - name: Register task definition revision
        id: reg
        run: |
          ARN=$(aws ecs register-task-definition \
            --cli-input-json file://taskdef.out.json \
            --query 'taskDefinition.taskDefinitionArn' --output text)
          echo "taskdef_arn=$ARN" >> "$GITHUB_OUTPUT"

      - name: Enforce single-instance capacity (ASG max=1 desired=1)
        if: github.event.inputs.enforce_single_instance == 'true'
        run: |
          ASG_ARN=$(aws ecs describe-capacity-providers --capacity-providers "${{ env.CP_NAME }}" --query 'capacityProviders[0].autoScalingGroupProvider.autoScalingGroupArn' --output text)
          ASG_NAME=$(echo "$ASG_ARN" | awk -F'autoScalingGroupName/' '{print $2}')
          aws autoscaling update-auto-scaling-group --auto-scaling-group-name "$ASG_NAME" --min-size 0 --max-size 1 --desired-capacity 1
          echo "ASG $ASG_NAME set to max=1 desired=1"

      - name: Run task via Capacity Provider (secrets from GitHub)
        id: run
        run: |
          # Build container env overrides; container name must match "train"
          OVERRIDES=$(jq -n \
            --arg mode "${{ github.event.inputs.mode }}" \
            --arg s3   "${{ secrets.S3_BUCKET }}" \
            --arg wandb "${{ secrets.WANDB_API_KEY }}" \
            '{ containerOverrides: [ { name: "train",
                environment: [
                  {name:"MODE",value:$mode},
                  {name:"S3_BUCKET",value:$s3},
                  {name:"WANDB_API_KEY",value:$wandb}
                ] } ] }')

          TASK_ARN=$(aws ecs run-task \
            --cluster "${{ env.CLUSTER }}" \
            --task-definition "${{ steps.reg.outputs.taskdef_arn }}" \
            --capacity-provider-strategy capacityProvider=${{ env.CP_NAME }},weight=1 \
            --count 1 \
            --network-configuration "awsvpcConfiguration={subnets=[${{ env.SUBNETS }}],securityGroups=[${{ env.SECURITY_GROUPS }}],assignPublicIp=DISABLED}" \
            --overrides "$OVERRIDES" \
            --query 'tasks[0].taskArn' --output text)

          echo "task_arn=$TASK_ARN" >> "$GITHUB_OUTPUT"

      - name: Wait and fail on non-zero exit
        run: |
          set +e
          CLUSTER="${{ env.CLUSTER }}"
          TASK_ARN="${{ steps.run.outputs.task_arn }}"
          # Simple long-poll loop (max ~3h)
          TIMEOUT_SEC=$((60 * 180))
          SLEEP=30
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT_SEC ]; do
            DESC=$(aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN")
            echo "$DESC" > task-desc.json
            STATUS=$(echo "$DESC" | jq -r '.tasks[0].lastStatus')
            CONT_STATUS=$(echo "$DESC" | jq -r '.tasks[0].containers[0].lastStatus // ""')
            CONT_REASON=$(echo "$DESC" | jq -r '.tasks[0].containers[0].reason // ""')
            ENI_STATUS=$(echo "$DESC" | jq -r '.tasks[0].attachments[0].status // ""')
            echo "lastStatus=$STATUS contStatus=$CONT_STATUS eni=$ENI_STATUS reason=$CONT_REASON elapsed=${ELAPSED}s"
            [ "$STATUS" = "STOPPED" ] && break
            sleep $SLEEP
            ELAPSED=$(( ELAPSED + SLEEP ))
          done
          if [ "$STATUS" != "STOPPED" ]; then
            echo "Timed out waiting for STOPPED"
            exit 255
          fi
          EXIT=$(jq -r '.tasks[0].containers[0].exitCode // empty' task-desc.json)
          REASON=$(jq -r '.tasks[0].stoppedReason // ""' task-desc.json)
          echo "ExitCode=$EXIT  Reason=$REASON"
          test "$EXIT" = "0"

      - name: Print last 200 log lines (best-effort)
        if: always()
        run: |
          TID=$(echo "${{ steps.run.outputs.task_arn }}" | awk -F'/' '{print $NF}')
          aws logs describe-log-streams --log-group-name "${{ env.LOG_GROUP }}" \
            --log-stream-name-prefix "train/train/$TID" \
            --query 'logStreams[0].logStreamName' --output text > stream.txt || true
          if [ -s stream.txt ]; then
            aws logs get-log-events --log-group-name "${{ env.LOG_GROUP }}" \
              --log-stream-name "$(cat stream.txt)" --limit 200 \
              --query 'events[].message' --output text || true
          fi

      - name: Optionally scale ASG to 0 if cluster idle
        if: always() && github.event.inputs.scale_down == 'true'
        run: |
          RUNNING=$(aws ecs list-tasks --cluster "${{ env.CLUSTER }}" --desired-status RUNNING --query 'taskArns' --output json)
          PENDING=$(aws ecs list-tasks --cluster "${{ env.CLUSTER }}" --desired-status PENDING --query 'taskArns' --output json)
          if [ "$RUNNING" = "[]" ] && [ "$PENDING" = "[]" ]; then
            ASG_ARN=$(aws ecs describe-capacity-providers --capacity-providers "${{ env.CP_NAME }}" --query 'capacityProviders[0].autoScalingGroupProvider.autoScalingGroupArn' --output text)
            ASG_NAME=$(echo "$ASG_ARN" | awk -F'autoScalingGroupName/' '{print $2}')
            aws autoscaling update-auto-scaling-group --auto-scaling-group-name "$ASG_NAME" --min-size 0 --desired-capacity 0
            echo "Scaled ASG $ASG_NAME to 0"
          else
            echo "Cluster not idle; skipping scale-down."
          fi